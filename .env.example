# =====================================
# LLM Provider Configuration
# =====================================

# Set the LLM provider to use: 'openai' or 'meta'
AZURE_LLM_MODEL=openai

# =====================================
# Streaming Configuration
# =====================================

# Enable/disable streaming response in Phase 6 (Backend)
# Default: True
STREAMING_RESPONSE=True

# Enable/disable streaming in frontend UI (Frontend)
# Default: True
ENABLE_STREAMING=True

# =====================================
# OpenAI Configuration (required if AZURE_LLM_MODEL=openai)
# =====================================

AZURE_OPENAI_API_KEY=your-openai-api-key-here
AZURE_OPENAI_ENDPOINT=https://your-openai-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_OPENAI_API_LLM_DEPLOYMENT_ID=gpt-4.1-mini
AZURE_OPENAI_LLM_MODEL=gpt-4.1-mini

# =====================================
# Meta Configuration (required if AZURE_LLM_MODEL=meta)
# =====================================

AZURE_META_API_KEY=your-meta-api-key-here
AZURE_META_ENDPOINT=https://your-meta-endpoint.services.ai.azure.com/models
AZURE_META_API_VERSION=2024-05-01-preview
AZURE_META_API_LLM_DEPLOYMENT_ID=Llama-4-Maverick-17B-128E-Instruct-FP8
AZURE_META_LLM_MODEL=Llama-4-Maverick-17B-128E-Instruct-FP8

# =====================================
# Other Required Variables
# =====================================

AZURE_COHERE_API_KEY=your-cohere-api-key-here
AZURE_COHERE_ENDPOINT=https://your-cohere-endpoint
MONGODB_CONNECTION_STRING=mongodb://localhost:27017/your-database
COLLECTION_NAME=your-collection-name
EMBEDDING_MODEL_NAME=your-embedding-model